{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zrmondsc/gedi_waveform_processor/blob/main/notebooks/export_rs_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Cloud Free Sentinel Mosaic\n",
        "This notebook was designed to run in **Google Colab**.\n",
        "It uses the Earth Engine Python API to generate cloud-free Sentinel-2 composites\n",
        "over your area of interest, defined from a local shapefile or GeoJSON.\n",
        "\n",
        "Getting Started:\n",
        "- Upload your shapefile or GeoJSON to Colab (or mount Google Drive)\n",
        "- Authenticate your Earth Engine account when prompted\n",
        "- Run the notebook below to generate a mosaic and visualize it on an interactive map"
      ],
      "metadata": {
        "id": "y5Eqot3dsddy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "⚠️ If you're not in Colab, you may need to adapt file paths and authentication flow."
      ],
      "metadata": {
        "id": "zeEwZR00uneE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import geopandas as gpd\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import ee"
      ],
      "metadata": {
        "id": "RMLc2pXBsssA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install geemap package\n",
        "import subprocess\n",
        "\n",
        "try:\n",
        "    import geemap\n",
        "except ImportError:\n",
        "    print('geemap package not installed. Installing ...')\n",
        "    subprocess.check_call([\"python\", '-m', 'pip', 'install', 'geemap']) # geemap Python package is built upon ipyleaflet and folium packages"
      ],
      "metadata": {
        "id": "MdEL2j--stsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Authenticate and Initialize GEE"
      ],
      "metadata": {
        "id": "WCFE_dpPsjrp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  ee.Initialize()\n",
        "except Exception as e:\n",
        "  ee.Authenticate()\n",
        "  ee.Initialize(project = \"ee-zmondo\")"
      ],
      "metadata": {
        "id": "-s6R6XLea6MN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Load AOI from shapefile / GeoJSON"
      ],
      "metadata": {
        "id": "nun1Vnmss50a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get path to cwd and set project root\n",
        "project_root = Path('/content')\n",
        "bbox_path = project_root / 'gedi_waveforms_tf_bbox.geojson'"
      ],
      "metadata": {
        "id": "s6sDzn70tXkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load bounding box geojson as a GeoDataFrame\n",
        "bbox_gdf = gpd.read_file(bbox_path).to_crs(\"EPSG:4326\")"
      ],
      "metadata": {
        "id": "_UpsIER-tBll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from shapely.geometry import mapping\n",
        "\n",
        "# Convert to an Earth Engine readable format (ee.FeatureCollection)\n",
        "def gdf_to_ee(gdf):\n",
        "  features = []\n",
        "  for _, row in gdf.iterrows():\n",
        "    geom_dict = mapping(row.geometry)\n",
        "    attrs = row.drop('geometry').to_dict()\n",
        "    feature = ee.Feature(geom_dict, attrs)\n",
        "    features.append(feature)\n",
        "  return ee.FeatureCollection(features)\n"
      ],
      "metadata": {
        "id": "Ykn2WYVQvlxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Define spatial and temporal boundaries"
      ],
      "metadata": {
        "id": "xjScLT7axlM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AOI = gdf_to_ee(bbox_gdf).geometry().buffer(1000)\n",
        "START_DATE = '2021-03-15'\n",
        "END_DATE = '2021-12-05'"
      ],
      "metadata": {
        "id": "RKZZnEAxwNQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Cloud masking Sentinel-2 with s2_cloudless and Mosaicking"
      ],
      "metadata": {
        "id": "JJ-oMMsvx45x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define masking parameters\n",
        "CLOUD_FILTER = 100\n",
        "CLD_PRB_THRESH = 30\n",
        "NIR_DRK_THRESH = 0.15\n",
        "CLD_PRJ_DIST = 1\n",
        "BUFFER = 50\n",
        "SR_SCALE = 1e4\n",
        "\n",
        "# Filter and join S2_SR_HARMONIZED with cloud probability\n",
        "def get_s2_sr_cld_col(aoi, start_date, end_date):\n",
        "    s2_sr = ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\") \\\n",
        "        .filterBounds(aoi) \\\n",
        "        .filterDate(start_date, end_date) \\\n",
        "        .filter(ee.Filter.lte('CLOUDY_PIXEL_PERCENTAGE', CLOUD_FILTER))\n",
        "\n",
        "    s2_cld = ee.ImageCollection(\"COPERNICUS/S2_CLOUD_PROBABILITY\") \\\n",
        "        .filterBounds(aoi) \\\n",
        "        .filterDate(start_date, end_date)\n",
        "\n",
        "    # Join collections by system:index\n",
        "    joined = ee.Join.saveFirst('s2cloudless').apply(**{\n",
        "        'primary': s2_sr,\n",
        "        'secondary': s2_cld,\n",
        "        'condition': ee.Filter.equals(leftField='system:index', rightField='system:index')\n",
        "    })\n",
        "\n",
        "    return ee.ImageCollection(joined)\n",
        "\n",
        "# Cloud detection\n",
        "def add_cloud_bands(img):\n",
        "    cld_prb = ee.Image(img.get('s2cloudless')).select('probability')\n",
        "    is_cloud = cld_prb.gt(CLD_PRB_THRESH).rename('clouds')\n",
        "    return img.addBands([cld_prb.rename('cloud_probability'), is_cloud])\n",
        "\n",
        "# Shadow detection\n",
        "def add_shadow_bands(img):\n",
        "    not_water = img.select('SCL').neq(6)\n",
        "    dark_pixels = img.select('B8').lt(NIR_DRK_THRESH * SR_SCALE).And(not_water).rename('dark_pixels')\n",
        "\n",
        "    shadow_azimuth = ee.Number(90).subtract(ee.Number(img.get('MEAN_SOLAR_AZIMUTH_ANGLE')))\n",
        "    cld_proj = img.select('clouds').directionalDistanceTransform(shadow_azimuth, CLD_PRJ_DIST * 10) \\\n",
        "        .reproject(crs=img.select(0).projection(), scale=100) \\\n",
        "        .select('distance').mask().rename('cloud_transform')\n",
        "\n",
        "    shadows = cld_proj.multiply(dark_pixels).rename('shadows')\n",
        "    return img.addBands([dark_pixels, cld_proj, shadows])\n",
        "\n",
        "# Combine cloud and shadow masks\n",
        "def add_cld_shdw_mask(img):\n",
        "    img = add_cloud_bands(img)\n",
        "    img = add_shadow_bands(img)\n",
        "    is_cld_shdw = img.select('clouds').add(img.select('shadows')).gt(0)\n",
        "\n",
        "    mask = is_cld_shdw.focal_min(2).focal_max(BUFFER * 2 / 20) \\\n",
        "        .reproject(crs=img.select(0).projection(), scale=20) \\\n",
        "        .rename('cloudmask')\n",
        "\n",
        "    return img.addBands(mask)\n",
        "\n",
        "# Apply mask to reflectance bands\n",
        "def apply_cld_shdw_mask(img):\n",
        "    mask = img.select('cloudmask').Not()\n",
        "    return img.select('B.*').updateMask(mask).copyProperties(img, img.propertyNames())\n",
        "\n",
        "# Generate mosaic\n",
        "def get_s2_mosaic(aoi, start_date, end_date):\n",
        "    col = get_s2_sr_cld_col(aoi, start_date, end_date) \\\n",
        "        .map(add_cld_shdw_mask) \\\n",
        "        .map(apply_cld_shdw_mask)\n",
        "    return col.median().clip(aoi)"
      ],
      "metadata": {
        "id": "5xY7CJmvx8pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mosaic = get_s2_mosaic(AOI, START_DATE, END_DATE)"
      ],
      "metadata": {
        "id": "BrHFk7fcyR4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Visualize cloud-free Sentinel-2 mosaic"
      ],
      "metadata": {
        "id": "46jRZ7k3yfVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize interactive map\n",
        "Map = geemap.Map()\n",
        "\n",
        "# Add basemap\n",
        "Map.add_basemap('HYBRID')\n",
        "\n",
        "# Define visualization parameters for RGB\n",
        "vis_params = {\n",
        "    'bands': ['B4', 'B3', 'B2'],\n",
        "    'min': 0.0,\n",
        "    'max': 3000\n",
        "}\n",
        "\n",
        "# Add the AOI\n",
        "Map.addLayer(AOI, {}, 'AOI')\n",
        "\n",
        "# Add sentinel-2 mosaic to map\n",
        "Map.addLayer(mosaic, vis_params, \"S2 Cloud-Free Mosaic\", True)\n",
        "\n",
        "# Zoom to AOI\n",
        "Map.centerObject(AOI, 10)\n",
        "\n",
        "\n",
        "Map"
      ],
      "metadata": {
        "id": "i0_QKg95yi6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Processing Sentinel-1 Imagery, Applying Lee Speckle Filter, and Mosaicking"
      ],
      "metadata": {
        "id": "cF1aDhXs82zP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Speckle Filtering functions\n",
        "# Credit: SERVIR-Mekong, adapted from\n",
        "# https://mygeoblog.com/2021/01/21/sentinel-1-speckle-filter-refined-lee/\n",
        "# Ported from JavaScript API to Python API with ChatGPT-4o\n",
        "\n",
        "def db_to_power(img):\n",
        "    \"\"\"\n",
        "    Converts a Sentinel-1 image from decibel (dB) scale to power scale.\n",
        "\n",
        "    Parameters:\n",
        "        img (ee.Image): Image in dB units.\n",
        "\n",
        "    Returns:\n",
        "        ee.Image: Image converted to power scale.\n",
        "    \"\"\"\n",
        "    return ee.Image(10).pow(img.divide(10))\n",
        "\n",
        "def power_to_db(img):\n",
        "    \"\"\"\n",
        "    Converts a Sentinel-1 image from power scale to decibel (dB) scale.\n",
        "\n",
        "    Parameters:\n",
        "        img (ee.Image): Image in power units.\n",
        "\n",
        "    Returns:\n",
        "        ee.Image: Image converted to dB scale.\n",
        "    \"\"\"\n",
        "    return ee.Image(10).multiply(img.log10())\n",
        "\n",
        "def refined_lee_full(image):\n",
        "    \"\"\"\n",
        "    Applies the full Refined Lee Speckle Filter to a multi-band Sentinel-1 image.\n",
        "\n",
        "    Parameters:\n",
        "        image (ee.Image): Multi-band SAR image in dB scale.\n",
        "\n",
        "    Returns:\n",
        "        ee.Image: Speckle-filtered image with original band names in dB scale.\n",
        "    \"\"\"\n",
        "    image = db_to_power(image)\n",
        "    band_names = image.bandNames()\n",
        "\n",
        "    def filter_band(band_name):\n",
        "        band_name = ee.String(band_name)\n",
        "        img = image.select(band_name)\n",
        "\n",
        "        # 3x3 mean and variance\n",
        "        kernel3 = ee.Kernel.square(1)\n",
        "        mean3 = img.reduceNeighborhood(ee.Reducer.mean(), kernel3)\n",
        "        var3 = img.reduceNeighborhood(ee.Reducer.variance(), kernel3)\n",
        "\n",
        "        # 7x7 sample kernel\n",
        "        sample_kernel = ee.Kernel.fixed(7, 7, [\n",
        "            [0,0,0,0,0,0,0],\n",
        "            [0,1,0,1,0,1,0],\n",
        "            [0,0,0,0,0,0,0],\n",
        "            [0,1,0,1,0,1,0],\n",
        "            [0,0,0,0,0,0,0],\n",
        "            [0,1,0,1,0,1,0],\n",
        "            [0,0,0,0,0,0,0]\n",
        "        ], 3, 3, False)\n",
        "\n",
        "        sample_mean = mean3.neighborhoodToBands(sample_kernel)\n",
        "        sample_var = var3.neighborhoodToBands(sample_kernel)\n",
        "\n",
        "        # Gradient directions\n",
        "        gradients = sample_mean.select(1).subtract(sample_mean.select(7)).abs() \\\n",
        "            .addBands(sample_mean.select(6).subtract(sample_mean.select(2)).abs()) \\\n",
        "            .addBands(sample_mean.select(3).subtract(sample_mean.select(5)).abs()) \\\n",
        "            .addBands(sample_mean.select(0).subtract(sample_mean.select(8)).abs())\n",
        "        max_grad = gradients.reduce(ee.Reducer.max())\n",
        "        gradmask = gradients.eq(max_grad)\n",
        "\n",
        "        # Direction mask (collapsed to single band)\n",
        "        directions = sample_mean.select(1).subtract(sample_mean.select(4)) \\\n",
        "            .gt(sample_mean.select(4).subtract(sample_mean.select(7))).multiply(1) \\\n",
        "            .add(sample_mean.select(6).subtract(sample_mean.select(4)) \\\n",
        "            .gt(sample_mean.select(4).subtract(sample_mean.select(2))).multiply(2)) \\\n",
        "            .add(sample_mean.select(3).subtract(sample_mean.select(4)) \\\n",
        "            .gt(sample_mean.select(4).subtract(sample_mean.select(5))).multiply(3)) \\\n",
        "            .add(sample_mean.select(0).subtract(sample_mean.select(4)) \\\n",
        "            .gt(sample_mean.select(4).subtract(sample_mean.select(8))).multiply(4))\n",
        "        # Opposite directions (5-8)\n",
        "        directions = directions \\\n",
        "            .add(directions.eq(0).multiply(5)) \\\n",
        "            .add(directions.eq(1).Not().multiply(6)) \\\n",
        "            .add(directions.eq(2).Not().multiply(7)) \\\n",
        "            .add(directions.eq(3).Not().multiply(8))\n",
        "\n",
        "        # Reduce mask to single band before applying\n",
        "        direction_mask = gradmask.reduce(ee.Reducer.anyNonZero())\n",
        "        directions = directions.updateMask(direction_mask)\n",
        "\n",
        "        # Noise estimate\n",
        "        sample_stats = sample_var.divide(sample_mean.multiply(sample_mean))\n",
        "        sigmaV = (\n",
        "            sample_stats.toArray()\n",
        "            .arraySort()\n",
        "            .arraySlice(0, 0, 5)\n",
        "            .arrayReduce(ee.Reducer.mean(), [0])\n",
        "            .arrayProject([0])\n",
        "            .arrayFlatten([['sigmaV']])\n",
        "            )\n",
        "\n",
        "        # Directional kernels\n",
        "        rect_weights = ee.List.repeat(ee.List.repeat(0, 7), 3).cat(ee.List.repeat(ee.List.repeat(1, 7), 4))\n",
        "        diag_weights = ee.List([\n",
        "            [1,0,0,0,0,0,0],\n",
        "            [1,1,0,0,0,0,0],\n",
        "            [1,1,1,0,0,0,0],\n",
        "            [1,1,1,1,0,0,0],\n",
        "            [1,1,1,1,1,0,0],\n",
        "            [1,1,1,1,1,1,0],\n",
        "            [1,1,1,1,1,1,1]\n",
        "        ])\n",
        "        rect_kernel = ee.Kernel.fixed(7, 7, rect_weights, 3, 3, False)\n",
        "        diag_kernel = ee.Kernel.fixed(7, 7, diag_weights, 3, 3, False)\n",
        "\n",
        "        dir_mean = img.reduceNeighborhood(ee.Reducer.mean(), rect_kernel).updateMask(directions.eq(1))\n",
        "        dir_var = img.reduceNeighborhood(ee.Reducer.variance(), rect_kernel).updateMask(directions.eq(1))\n",
        "        dir_mean = dir_mean.addBands(img.reduceNeighborhood(ee.Reducer.mean(), diag_kernel).updateMask(directions.eq(2)))\n",
        "        dir_var = dir_var.addBands(img.reduceNeighborhood(ee.Reducer.variance(), diag_kernel).updateMask(directions.eq(2)))\n",
        "\n",
        "        for i in range(1, 4):\n",
        "            dir_mean = dir_mean.addBands(img.reduceNeighborhood(ee.Reducer.mean(), rect_kernel.rotate(i)).updateMask(directions.eq(2*i+1)))\n",
        "            dir_var = dir_var.addBands(img.reduceNeighborhood(ee.Reducer.variance(), rect_kernel.rotate(i)).updateMask(directions.eq(2*i+1)))\n",
        "            dir_mean = dir_mean.addBands(img.reduceNeighborhood(ee.Reducer.mean(), diag_kernel.rotate(i)).updateMask(directions.eq(2*i+2)))\n",
        "            dir_var = dir_var.addBands(img.reduceNeighborhood(ee.Reducer.variance(), diag_kernel.rotate(i)).updateMask(directions.eq(2*i+2)))\n",
        "\n",
        "        dir_mean = dir_mean.reduce(ee.Reducer.sum())\n",
        "        dir_var = dir_var.reduce(ee.Reducer.sum())\n",
        "\n",
        "        varX = dir_var.subtract(dir_mean.multiply(dir_mean).multiply(sigmaV)).divide(sigmaV.add(1.0))\n",
        "        b = varX.divide(dir_var)\n",
        "        result = dir_mean.add(b.multiply(img.subtract(dir_mean)))\n",
        "\n",
        "        return power_to_db(result).rename(band_name)\n",
        "\n",
        "    # Map over bands server-side using iterate\n",
        "    def wrap_band(band_name, prev_result):\n",
        "        prev_img = ee.Image(prev_result)\n",
        "        return prev_img.addBands(filter_band(band_name))\n",
        "\n",
        "    empty = ee.Image().select()\n",
        "    filtered = band_names.iterate(wrap_band, empty)\n",
        "\n",
        "    # Return and preserve metadata\n",
        "    return ee.Image(filtered).copyProperties(image, image.propertyNames())\n"
      ],
      "metadata": {
        "id": "UCjIVnrz1q6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Speckle Filtering function\n",
        "# Credit: SERVIR-Mekong, adapted from\n",
        "# https://mygeoblog.com/2021/01/21/sentinel-1-speckle-filter-refined-lee/\n",
        "# Source: https://colab.research.google.com/github/johrosa/ls-FloodMonitoring/blob/main/country_scale_flood_detection.ipynb#scrollTo=np9c5KV1Z3tt\n",
        "\n",
        "def refinedLee(image):\n",
        "    '''\n",
        "    # Source: https://colab.research.google.com/github/johrosa/ls-FloodMonitoring/blob/main/country_scale_flood_detection.ipynb#scrollTo=np9c5KV1Z3tt\n",
        "\n",
        "    Apply Lee Speckle Filter on ee.Image() object.\n",
        "    Adapted From:\n",
        "      Mullissa, A., Vollrath, A., Odongo-Braun, C., Slagter, B., Balling, J., Gou, Y., Gorelick, N., Reiche, J., 2021.\n",
        "    Sentinel-1 SAR Backscatter Analysis Ready Data Preparation in Google Earth Engine. Remote Sensing 13, 1954.\n",
        "    https://doi.org/10.3390/rs13101954\n",
        "\n",
        "    '''\n",
        "    bandNames = image.bandNames().remove('angle')\n",
        "\n",
        "    def filterForBands(bn):\n",
        "        bn = ee.String(bn)\n",
        "        img = image.select([bn]).resample('bilinear')\n",
        "\n",
        "        weights3 = ee.List.repeat(ee.List.repeat(1, 3), 3)\n",
        "        kernel3 = ee.Kernel.fixed(3, 3, weights3, 1, 1, False)\n",
        "        mean3 = img.reduceNeighborhood(ee.Reducer.mean(), kernel3)\n",
        "        variance3 = img.reduceNeighborhood(ee.Reducer.variance(), kernel3)\n",
        "\n",
        "        sample_weights = ee.List([\n",
        "            [0,0,0,0,0,0,0],\n",
        "            [0,1,0,1,0,1,0],\n",
        "            [0,0,0,0,0,0,0],\n",
        "            [0,1,0,1,0,1,0],\n",
        "            [0,0,0,0,0,0,0],\n",
        "            [0,1,0,1,0,1,0],\n",
        "            [0,0,0,0,0,0,0]\n",
        "        ])\n",
        "        sample_kernel = ee.Kernel.fixed(7, 7, sample_weights, 3, 3, False)\n",
        "\n",
        "        sample_mean = mean3.neighborhoodToBands(sample_kernel)\n",
        "        sample_var = variance3.neighborhoodToBands(sample_kernel)\n",
        "\n",
        "        gradients = sample_mean.select(1).subtract(sample_mean.select(7)).abs() \\\n",
        "            .addBands(sample_mean.select(6).subtract(sample_mean.select(2)).abs()) \\\n",
        "            .addBands(sample_mean.select(3).subtract(sample_mean.select(5)).abs()) \\\n",
        "            .addBands(sample_mean.select(0).subtract(sample_mean.select(8)).abs())\n",
        "        max_gradient = gradients.reduce(ee.Reducer.max())\n",
        "        gradmask = gradients.eq(max_gradient).addBands(gradients.eq(max_gradient))\n",
        "\n",
        "        directions = sample_mean.select(1).subtract(sample_mean.select(4)) \\\n",
        "            .gt(sample_mean.select(4).subtract(sample_mean.select(7))).multiply(1) \\\n",
        "            .addBands(sample_mean.select(6).subtract(sample_mean.select(4)) \\\n",
        "            .gt(sample_mean.select(4).subtract(sample_mean.select(2))).multiply(2)) \\\n",
        "            .addBands(sample_mean.select(3).subtract(sample_mean.select(4)) \\\n",
        "            .gt(sample_mean.select(4).subtract(sample_mean.select(5))).multiply(3)) \\\n",
        "            .addBands(sample_mean.select(0).subtract(sample_mean.select(4)) \\\n",
        "            .gt(sample_mean.select(4).subtract(sample_mean.select(8))).multiply(4)) \\\n",
        "            .addBands(sample_mean.select(1).subtract(sample_mean.select(4)).lte(sample_mean.select(4).subtract(sample_mean.select(7))).multiply(5)) \\\n",
        "            .addBands(sample_mean.select(6).subtract(sample_mean.select(4)).lte(sample_mean.select(4).subtract(sample_mean.select(2))).multiply(6)) \\\n",
        "            .addBands(sample_mean.select(3).subtract(sample_mean.select(4)).lte(sample_mean.select(4).subtract(sample_mean.select(5))).multiply(7)) \\\n",
        "            .addBands(sample_mean.select(0).subtract(sample_mean.select(4)).lte(sample_mean.select(4).subtract(sample_mean.select(8))).multiply(8))\n",
        "\n",
        "        directions = directions.updateMask(gradmask).reduce(ee.Reducer.sum())\n",
        "\n",
        "        sample_stats = sample_var.divide(sample_mean.multiply(sample_mean))\n",
        "        sigmaV = sample_stats.toArray().arraySort().arraySlice(0, 0, 5).arrayReduce(ee.Reducer.mean(), [0])\n",
        "\n",
        "        rect_weights = ee.List.repeat(ee.List.repeat(0, 7), 3).cat(ee.List.repeat(ee.List.repeat(1, 7), 4))\n",
        "        diag_weights = ee.List([\n",
        "            [1,0,0,0,0,0,0],\n",
        "            [1,1,0,0,0,0,0],\n",
        "            [1,1,1,0,0,0,0],\n",
        "            [1,1,1,1,0,0,0],\n",
        "            [1,1,1,1,1,0,0],\n",
        "            [1,1,1,1,1,1,0],\n",
        "            [1,1,1,1,1,1,1]\n",
        "        ])\n",
        "\n",
        "        rect_kernel = ee.Kernel.fixed(7, 7, rect_weights, 3, 3, False)\n",
        "        diag_kernel = ee.Kernel.fixed(7, 7, diag_weights, 3, 3, False)\n",
        "\n",
        "        dir_mean = img.reduceNeighborhood(ee.Reducer.mean(), rect_kernel).updateMask(directions.eq(1))\n",
        "        dir_var = img.reduceNeighborhood(ee.Reducer.variance(), rect_kernel).updateMask(directions.eq(1))\n",
        "\n",
        "        dir_mean = dir_mean.addBands(img.reduceNeighborhood(ee.Reducer.mean(), diag_kernel).updateMask(directions.eq(2)))\n",
        "        dir_var = dir_var.addBands(img.reduceNeighborhood(ee.Reducer.variance(), diag_kernel).updateMask(directions.eq(2)))\n",
        "\n",
        "        for i in range(1, 4):\n",
        "            angle = i * 90\n",
        "            dir_mean = dir_mean.addBands(img.reduceNeighborhood(ee.Reducer.mean(), rect_kernel.rotate(angle)).updateMask(directions.eq(2*i+1)))\n",
        "            dir_var = dir_var.addBands(img.reduceNeighborhood(ee.Reducer.variance(), rect_kernel.rotate(angle)).updateMask(directions.eq(2*i+1)))\n",
        "            dir_mean = dir_mean.addBands(img.reduceNeighborhood(ee.Reducer.mean(), diag_kernel.rotate(angle)).updateMask(directions.eq(2*i+2)))\n",
        "            dir_var = dir_var.addBands(img.reduceNeighborhood(ee.Reducer.variance(), diag_kernel.rotate(angle)).updateMask(directions.eq(2*i+2)))\n",
        "\n",
        "        dir_mean = dir_mean.reduce(ee.Reducer.sum())\n",
        "        dir_var = dir_var.reduce(ee.Reducer.sum())\n",
        "\n",
        "        varX = dir_var.subtract(dir_mean.multiply(dir_mean).multiply(sigmaV)).divide(sigmaV.add(1.0))\n",
        "        b = varX.divide(dir_var)\n",
        "\n",
        "        filtered = dir_mean.add(b.multiply(img.subtract(dir_mean)))\\\n",
        "          .arrayProject([0])\\\n",
        "          .arrayFlatten([['sum']])\\\n",
        "          .float()\n",
        "        return filtered\n",
        "\n",
        "    # Apply filter over bands\n",
        "    filtered = ee.ImageCollection(bandNames.map(filterForBands)).toBands().rename(bandNames)\n",
        "\n",
        "    # Add back, overwriting bands\n",
        "    return image.addBands(filtered, None, True)"
      ],
      "metadata": {
        "id": "lNxMIeiZp5pL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_s1_mosaic(aoi, start_date, end_date,\n",
        "                                   polarizations=['VV', 'VH'],\n",
        "                                   orbit='ASCENDING',\n",
        "                                   reducer='median'):\n",
        "    \"\"\"\n",
        "    Creates a Sentinel-1 mosaic for the given time range and AOI,\n",
        "    applying the full Refined Lee speckle filter to each image.\n",
        "\n",
        "    Parameters:\n",
        "        aoi (ee.Geometry): Area of interest.\n",
        "        start_date (str): Start date (YYYY-MM-DD).\n",
        "        end_date (str): End date (YYYY-MM-DD).\n",
        "        polarizations (list): List of polarizations to include (e.g. ['VV', 'VH']).\n",
        "        orbit (str): Orbit pass ('ASCENDING', 'DESCENDING', or 'BOTH').\n",
        "        reducer (str): Reducer to apply over time ('median', 'mean', 'max', 'mosaic').\n",
        "\n",
        "    Returns:\n",
        "        ee.Image: A speckle-filtered S1 composite clipped to AOI.\n",
        "    \"\"\"\n",
        "    s1 = (\n",
        "        ee.ImageCollection(\"COPERNICUS/S1_GRD\")\n",
        "        .filterBounds(aoi)\n",
        "        .filterDate(start_date, end_date)\n",
        "        .filter(ee.Filter.eq('instrumentMode', 'IW'))\n",
        "        .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))\n",
        "        .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))\n",
        "        .filter(ee.Filter.eq('resolution_meters', 10))\n",
        "        .select(polarizations)\n",
        "    )\n",
        "\n",
        "    if orbit in ['ASCENDING', 'DESCENDING']:\n",
        "        s1 = s1.filter(ee.Filter.eq('orbitProperties_pass', orbit))\n",
        "\n",
        "    # # Apply full refined Lee filter\n",
        "    s1_filtered = s1.map(refinedLee)\n",
        "\n",
        "    # Reduce to a single mosaic\n",
        "    if reducer == 'median':\n",
        "        return s1_filtered.median().clip(aoi)\n",
        "    elif reducer == 'mean':\n",
        "        return s1_filtered.mean().clip(aoi)\n",
        "    elif reducer == 'max':\n",
        "        return s1_filtered.max().clip(aoi)\n",
        "    elif reducer == 'mosaic':\n",
        "        return s1_filtered.mosaic().clip(aoi)\n",
        "    else:\n",
        "        raise ValueError(\"Reducer must be one of: median, mean, max, mosaic\")"
      ],
      "metadata": {
        "id": "arnPTkxu_kJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define temporal filters\n",
        "S1_START_DATE = '2021-06-01'\n",
        "S1_END_DATE = '2021-08-01'"
      ],
      "metadata": {
        "id": "3WFmq5WZ6iwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity Check\n",
        "\n",
        "# Apply refinedLee function and mosaic\n",
        "s1_filtered = get_s1_mosaic(AOI, S1_START_DATE, S1_END_DATE)\n",
        "\n",
        "# Get point inside the AOI\n",
        "point = AOI.centroid()\n",
        "\n",
        "# Get the value of filtered S1 mosaic at point\n",
        "value = s1_filtered.reduceRegion(\n",
        "    reducer=ee.Reducer.first(),\n",
        "    geometry=point,\n",
        "    scale=10,\n",
        "    maxPixels=1e9\n",
        ").getInfo()\n",
        "\n",
        "print(value)\n"
      ],
      "metadata": {
        "id": "P1n9Qikosb2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply speckle filter function and mosaic\n",
        "s1_mosaic = get_s1_mosaic(AOI, S1_START_DATE, S1_END_DATE)"
      ],
      "metadata": {
        "id": "RWj80QOHDJQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Visualize Processed Sentinel-1 Mosaic"
      ],
      "metadata": {
        "id": "OToD1a1kDOJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add S1 VV and VH layers to existing map instance\n",
        "Map.addLayer(s1_mosaic.select('VV'), {'min': -20, 'max': 0}, 'S1 VV, Lee Filtered')\n",
        "Map.addLayer(s1_mosaic.select('VH'), {'min': -25, 'max': -5}, 'S1 VH, Lee Filtered')\n",
        "Map"
      ],
      "metadata": {
        "id": "yKLWJRaX6rDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Combine Sentinel Bands, Resample and Reproject"
      ],
      "metadata": {
        "id": "A-Y-eV5YN5h5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create combined Sentinel-1 and Sentinel-2 image\n",
        "sentinel_combined = mosaic.addBands(s1_mosaic)\n",
        "\n",
        "# add XY coordinate bands\n",
        "sentinel_combined # inspect the combined sentinel image"
      ],
      "metadata": {
        "id": "4IaVARTPGtBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a reference projection\n",
        "ref_proj = ee.Projection('EPSG: 4326').atScale(10)\n",
        "\n",
        "# Set the projection of our mosaicked dataset to the reference projection\n",
        "sentinel_combined = sentinel_combined.setDefaultProjection(ref_proj)\n",
        "\n",
        "# Set export CRS\n",
        "utm_crs = 'EPSG:32648'\n",
        "\n",
        "# Reduce resolution to 25m and reproject to force alignment\n",
        "sentinel_reprojected =sentinel_combined.reduceResolution(\n",
        "    reducer = ee.Reducer.mean(),\n",
        "    maxPixels = 128\n",
        ").reproject(\n",
        "    crs = utm_crs,\n",
        "    scale = 25\n",
        ")"
      ],
      "metadata": {
        "id": "ujH2SwV4k91j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Export Training and Testing Patches to Google Cloud Storage"
      ],
      "metadata": {
        "id": "VPbymde9oCNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load GEDI metadata and latent vectors\n",
        "gedi_npz = np.load(\"/content/encoded_latents_09.npz\")\n",
        "latents = gedi_npz['latents']\n",
        "coords = gedi_npz['metadata'][:, :2]  # lat, lon"
      ],
      "metadata": {
        "id": "N6qwB-VEwxIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from shapely.geometry import Point\n",
        "\n",
        "# Create GeoDataFrame\n",
        "gedi_gdf = gpd.GeoDataFrame(geometry=[Point(lon, lat) for lat, lon in coords], crs=\"EPSG:4326\")\n",
        "gedi_gdf[\"lat\"] = coords[:, 0]\n",
        "gedi_gdf[\"lon\"] = coords[:, 1]\n",
        "gedi_gdf[\"latent_index\"] = np.arange(len(coords))\n",
        "gedi_gdf['latents'] = list(latents)\n",
        "gedi_gdf = gedi_gdf.to_crs(\"EPSG: 32648\")"
      ],
      "metadata": {
        "id": "fywTKghdlxdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gdf_to_ee_fc(gdf, id_column='latent_index'):\n",
        "    features = []\n",
        "    for _, row in gdf.iterrows():\n",
        "        geom = mapping(row.geometry)\n",
        "        latent_values = [float(x) for x in row['latents']]\n",
        "\n",
        "        # Build properties with individual latent components\n",
        "        props = {f\"latent_{i}\": val for i, val in enumerate(latent_values)}\n",
        "        props[id_column] = int(row[id_column])\n",
        "\n",
        "        features.append(ee.Feature(geom, props))\n",
        "    return ee.FeatureCollection(features)\n",
        "\n",
        "gedi_fc = gdf_to_ee_fc(gedi_gdf)"
      ],
      "metadata": {
        "id": "hr1ALUnJ6AW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gedi_fc.first().getInfo()"
      ],
      "metadata": {
        "id": "IKsXDAiPp5wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define bands to use\n",
        "BANDS = ['VV', 'VH', 'B2', 'B3', 'B4', 'B5', 'B6',\n",
        "         'B7', 'B8', 'B8A', 'B11', 'B12']\n",
        "\n",
        "# Define patch size and kernel\n",
        "PATCH_SIZE = 3\n",
        "KERNEL = ee.Kernel.square(PATCH_SIZE // 2)\n",
        "\n",
        "def create_patch_image(image, bands):\n",
        "    patches = [image.select(b).neighborhoodToArray(KERNEL) for b in bands]\n",
        "    return ee.Image.cat(patches).rename([f\"{b}_patch\" for b in bands])\n",
        "\n",
        "patch_image = create_patch_image(sentinel_reprojected, BANDS)"
      ],
      "metadata": {
        "id": "DwiBPw1TvQXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample patches at GEDI points\n",
        "sampled = patch_image.sampleRegions(\n",
        "    collection=gedi_fc,\n",
        "    scale=25,  # match your 25m resolution\n",
        "    geometries=False,  # don't include geometries in output\n",
        "    tileScale=16\n",
        ")"
      ],
      "metadata": {
        "id": "_XtXkHuzvpyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Sample single pixel value at GEDI points\n",
        "# sampled = sentinel_reprojected.select(BANDS).sampleRegions(\n",
        "#     collection=gedi_fc,\n",
        "#     scale=25,  # same 25m resolution\n",
        "#     geometries=False,\n",
        "#     tileScale=16\n",
        "# )"
      ],
      "metadata": {
        "id": "78nsj8L7j62J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export as TFRecord for TensorFlow\n",
        "export_task = ee.batch.Export.table.toCloudStorage(\n",
        "    collection=sampled,\n",
        "    description='export_gedi_sentinel_patches',\n",
        "    bucket='ee-gedi-data',  # ⬅️ change this to your GCS bucket\n",
        "    fileNamePrefix='tfrecords/gedi_latent_patches_3x3_utm',\n",
        "    fileFormat='TFRecord'\n",
        ")\n",
        "\n",
        "export_task.start()"
      ],
      "metadata": {
        "id": "8qTUzYqCwDUp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}