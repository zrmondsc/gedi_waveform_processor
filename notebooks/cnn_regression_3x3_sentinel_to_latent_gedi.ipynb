{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPOAizUE+UsjEXM8M/Q2who",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zrmondsc/gedi_waveform_processor/blob/main/notebooks/cnn_regression_3x3_sentinel_to_latent_gedi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zNbRYlREDpi9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Authentication"
      ],
      "metadata": {
        "id": "89aFBHZtDoym"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "meqrggj2CMMo"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "Z4MrQETSCla1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Load and parse tfrecord.gz dataset"
      ],
      "metadata": {
        "id": "2LA4CJZsFQhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset from Google Cloud Storage\n",
        "tfrecord_path = 'gs://ee-gedi-data/tfrecords/gedi_latent_patches_3x3.tfrecord.gz'\n",
        "raw_dataset = tf.data.TFRecordDataset(tfrecord_path, compression_type='GZIP')"
      ],
      "metadata": {
        "id": "VoOzo5mYDWdJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentinel bands and patch size\n",
        "BANDS = ['VV', 'VH', 'B2', 'B3', 'B4', 'B5', 'B6',\n",
        "         'B7', 'B8', 'B8A', 'B11', 'B12']\n",
        "LATENT_KEYS = [f\"latent_{i}\" for i in range(8)]\n",
        "PATCH_SIZE = 3\n",
        "\n",
        "# Feature schema\n",
        "feature_description = {\n",
        "    f\"{band}_patch\": tf.io.FixedLenFeature([PATCH_SIZE * PATCH_SIZE], tf.float32)\n",
        "    for band in BANDS\n",
        "}\n",
        "feature_description.update({\n",
        "    key: tf.io.FixedLenFeature([], tf.float32) for key in LATENT_KEYS\n",
        "})\n",
        "\n",
        "# Parser function\n",
        "def parse_example(example_proto):\n",
        "    example = tf.io.parse_single_example(example_proto, feature_description)\n",
        "\n",
        "    # Reconstruct patch: [3, 3, 12]\n",
        "    patch = tf.stack([\n",
        "        tf.reshape(example[f\"{band}_patch\"], [PATCH_SIZE, PATCH_SIZE])\n",
        "        for band in BANDS\n",
        "    ], axis=-1)\n",
        "\n",
        "    # Combine latents into [8] vector\n",
        "    latents = tf.stack([example[key] for key in LATENT_KEYS])\n",
        "\n",
        "    return patch, latents"
      ],
      "metadata": {
        "id": "tomC2bm8C-t1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parse dataset\n",
        "parsed_dataset = raw_dataset.map(parse_example)\n",
        "parsed_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5JJwwJCDMck",
        "outputId": "2116f444-0747-4225-c578-2d243ef92a0a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_MapDataset element_spec=(TensorSpec(shape=(3, 3, 12), dtype=tf.float32, name=None), TensorSpec(shape=(8,), dtype=tf.float32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Split data into training and testing datasets"
      ],
      "metadata": {
        "id": "Wc1neuZ8FX3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "X, y = [], []\n",
        "\n",
        "# Convert tensors to numpy arrays\n",
        "for patch, latents in tqdm(parsed_dataset):\n",
        "    X.append(patch.numpy())\n",
        "    y.append(latents.numpy())\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHvZ6usxF1UK",
        "outputId": "cd02db0e-4d1a-40f7-cf11-11df94574ec4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10546it [00:06, 1540.05it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split numpy arrays with sk-learn\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVgmTr6AF5KG",
        "outputId": "f61ee36a-bee0-4527-8c8a-0149af1c45aa"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (7382, 3, 3, 12)\n",
            "X_test shape: (3164, 3, 3, 12)\n",
            "y_train shape: (7382, 8)\n",
            "y_test shape: (3164, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert back to a tensor and batch\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(64).prefetch(tf.data.AUTOTUNE)\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(64).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "xGABlPicGfYy"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Build and compile CNN"
      ],
      "metadata": {
        "id": "VN_eCHMEHRPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def build_model():\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(3, 3, 12)),         # your Sentinel patch\n",
        "        layers.Conv2D(64, (2, 2), activation='relu'),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(8)  # 8D output = GEDI latent vector\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "model = build_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "BF1DW40-HhyX",
        "outputId": "beb61eca-599c-4603-e9d0-4f40faae018e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │           \u001b[38;5;34m3,136\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m16,448\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m520\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,136</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,104\u001b[0m (78.53 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,104</span> (78.53 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,104\u001b[0m (78.53 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,104</span> (78.53 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='mse',\n",
        "    metrics=['mae']\n",
        ")"
      ],
      "metadata": {
        "id": "ua2WTv0iHkYB"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=150\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMdedQm6Hpkw",
        "outputId": "e90be38d-0c13-49b1-9c53-46716978f178"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 49344.4531 - mae: 114.8361 - val_loss: 711.0732 - val_mae: 20.0155\n",
            "Epoch 2/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 640.6285 - mae: 18.8920 - val_loss: 402.0988 - val_mae: 15.0487\n",
            "Epoch 3/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 376.3176 - mae: 14.5021 - val_loss: 290.9688 - val_mae: 12.8686\n",
            "Epoch 4/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 271.5208 - mae: 12.3785 - val_loss: 216.9597 - val_mae: 11.1250\n",
            "Epoch 5/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 210.5602 - mae: 10.9553 - val_loss: 172.9533 - val_mae: 9.9710\n",
            "Epoch 6/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 170.6009 - mae: 9.8851 - val_loss: 144.5483 - val_mae: 9.1270\n",
            "Epoch 7/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 141.9393 - mae: 9.0237 - val_loss: 124.6719 - val_mae: 8.4827\n",
            "Epoch 8/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 121.3621 - mae: 8.3576 - val_loss: 106.2254 - val_mae: 7.8368\n",
            "Epoch 9/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 107.2409 - mae: 7.8746 - val_loss: 92.3715 - val_mae: 7.3194\n",
            "Epoch 10/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 94.1981 - mae: 7.4083 - val_loss: 83.9878 - val_mae: 7.0019\n",
            "Epoch 11/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 84.5186 - mae: 7.0301 - val_loss: 77.6353 - val_mae: 6.7476\n",
            "Epoch 12/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 76.5416 - mae: 6.7021 - val_loss: 71.2286 - val_mae: 6.4580\n",
            "Epoch 13/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 69.5367 - mae: 6.3832 - val_loss: 69.3378 - val_mae: 6.3858\n",
            "Epoch 14/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 63.7632 - mae: 6.1113 - val_loss: 66.0440 - val_mae: 6.2443\n",
            "Epoch 15/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 57.8018 - mae: 5.8213 - val_loss: 58.1244 - val_mae: 5.8575\n",
            "Epoch 16/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 52.2612 - mae: 5.5433 - val_loss: 51.8920 - val_mae: 5.5547\n",
            "Epoch 17/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 48.1641 - mae: 5.3305 - val_loss: 45.9691 - val_mae: 5.2227\n",
            "Epoch 18/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 44.2461 - mae: 5.1092 - val_loss: 39.7405 - val_mae: 4.8354\n",
            "Epoch 19/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 40.7980 - mae: 4.9115 - val_loss: 37.5070 - val_mae: 4.7107\n",
            "Epoch 20/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 38.2702 - mae: 4.7643 - val_loss: 35.9354 - val_mae: 4.6240\n",
            "Epoch 21/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 36.2215 - mae: 4.6376 - val_loss: 35.7315 - val_mae: 4.6348\n",
            "Epoch 22/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 34.6083 - mae: 4.5369 - val_loss: 32.7436 - val_mae: 4.4306\n",
            "Epoch 23/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 33.6237 - mae: 4.4833 - val_loss: 29.6311 - val_mae: 4.2045\n",
            "Epoch 24/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 32.3915 - mae: 4.4082 - val_loss: 29.9574 - val_mae: 4.2478\n",
            "Epoch 25/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 30.9094 - mae: 4.3124 - val_loss: 31.2439 - val_mae: 4.3728\n",
            "Epoch 26/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.5971 - mae: 4.2270 - val_loss: 28.4638 - val_mae: 4.1702\n",
            "Epoch 27/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.8441 - mae: 4.0998 - val_loss: 24.6501 - val_mae: 3.8692\n",
            "Epoch 28/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.8041 - mae: 4.0204 - val_loss: 23.0886 - val_mae: 3.7429\n",
            "Epoch 29/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 25.6558 - mae: 3.9330 - val_loss: 21.0437 - val_mae: 3.5584\n",
            "Epoch 30/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 24.9014 - mae: 3.8737 - val_loss: 20.0888 - val_mae: 3.4698\n",
            "Epoch 31/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 23.9261 - mae: 3.7991 - val_loss: 19.8062 - val_mae: 3.4485\n",
            "Epoch 32/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 22.7913 - mae: 3.7080 - val_loss: 19.6172 - val_mae: 3.4426\n",
            "Epoch 33/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 21.5722 - mae: 3.6111 - val_loss: 19.2200 - val_mae: 3.4298\n",
            "Epoch 34/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 21.4470 - mae: 3.6065 - val_loss: 19.1433 - val_mae: 3.4365\n",
            "Epoch 35/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 20.9583 - mae: 3.5712 - val_loss: 19.0425 - val_mae: 3.4330\n",
            "Epoch 36/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.9874 - mae: 3.4889 - val_loss: 18.9241 - val_mae: 3.4232\n",
            "Epoch 37/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 19.0106 - mae: 3.3999 - val_loss: 18.1963 - val_mae: 3.3411\n",
            "Epoch 38/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 17.9612 - mae: 3.3007 - val_loss: 18.2458 - val_mae: 3.3506\n",
            "Epoch 39/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 17.7335 - mae: 3.2847 - val_loss: 20.5598 - val_mae: 3.6083\n",
            "Epoch 40/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 17.8880 - mae: 3.3071 - val_loss: 21.6881 - val_mae: 3.7361\n",
            "Epoch 41/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 17.4932 - mae: 3.2729 - val_loss: 21.1221 - val_mae: 3.6955\n",
            "Epoch 42/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 16.8421 - mae: 3.2117 - val_loss: 20.2043 - val_mae: 3.6176\n",
            "Epoch 43/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 16.1758 - mae: 3.1491 - val_loss: 19.9199 - val_mae: 3.5779\n",
            "Epoch 44/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 15.8512 - mae: 3.1170 - val_loss: 18.9267 - val_mae: 3.4721\n",
            "Epoch 45/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 15.4178 - mae: 3.0759 - val_loss: 18.0679 - val_mae: 3.3720\n",
            "Epoch 46/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 15.1535 - mae: 3.0511 - val_loss: 17.3794 - val_mae: 3.2960\n",
            "Epoch 47/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 14.6662 - mae: 2.9996 - val_loss: 16.8566 - val_mae: 3.2393\n",
            "Epoch 48/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 14.3364 - mae: 2.9669 - val_loss: 16.5066 - val_mae: 3.2018\n",
            "Epoch 49/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14.0368 - mae: 2.9370 - val_loss: 16.3999 - val_mae: 3.1912\n",
            "Epoch 50/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 13.4221 - mae: 2.8708 - val_loss: 15.9392 - val_mae: 3.1413\n",
            "Epoch 51/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 12.9341 - mae: 2.8162 - val_loss: 14.9338 - val_mae: 3.0396\n",
            "Epoch 52/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 12.6524 - mae: 2.7892 - val_loss: 14.8800 - val_mae: 3.0314\n",
            "Epoch 53/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 12.1387 - mae: 2.7303 - val_loss: 14.4714 - val_mae: 2.9933\n",
            "Epoch 54/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 11.7081 - mae: 2.6803 - val_loss: 13.6622 - val_mae: 2.9149\n",
            "Epoch 55/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11.3797 - mae: 2.6434 - val_loss: 13.0343 - val_mae: 2.8541\n",
            "Epoch 56/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 11.1090 - mae: 2.6122 - val_loss: 11.6445 - val_mae: 2.7055\n",
            "Epoch 57/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 10.8375 - mae: 2.5806 - val_loss: 10.3275 - val_mae: 2.5471\n",
            "Epoch 58/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 10.5705 - mae: 2.5478 - val_loss: 9.1019 - val_mae: 2.3804\n",
            "Epoch 59/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 10.2315 - mae: 2.5038 - val_loss: 8.3180 - val_mae: 2.2621\n",
            "Epoch 60/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.8502 - mae: 2.4522 - val_loss: 8.1104 - val_mae: 2.2307\n",
            "Epoch 61/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.6647 - mae: 2.4298 - val_loss: 7.9638 - val_mae: 2.2048\n",
            "Epoch 62/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.4138 - mae: 2.3961 - val_loss: 7.8621 - val_mae: 2.1890\n",
            "Epoch 63/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.2490 - mae: 2.3727 - val_loss: 8.0123 - val_mae: 2.2127\n",
            "Epoch 64/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.1147 - mae: 2.3570 - val_loss: 8.3582 - val_mae: 2.2683\n",
            "Epoch 65/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.0479 - mae: 2.3463 - val_loss: 8.4817 - val_mae: 2.2881\n",
            "Epoch 66/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.6925 - mae: 2.2982 - val_loss: 8.4325 - val_mae: 2.2801\n",
            "Epoch 67/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.3973 - mae: 2.2619 - val_loss: 8.3561 - val_mae: 2.2690\n",
            "Epoch 68/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.0173 - mae: 2.2049 - val_loss: 8.2194 - val_mae: 2.2459\n",
            "Epoch 69/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7.9494 - mae: 2.1948 - val_loss: 7.7978 - val_mae: 2.1849\n",
            "Epoch 70/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 7.7976 - mae: 2.1743 - val_loss: 7.6709 - val_mae: 2.1658\n",
            "Epoch 71/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.6263 - mae: 2.1507 - val_loss: 7.3600 - val_mae: 2.1210\n",
            "Epoch 72/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.5538 - mae: 2.1411 - val_loss: 7.1640 - val_mae: 2.0929\n",
            "Epoch 73/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.3106 - mae: 2.1051 - val_loss: 6.8934 - val_mae: 2.0514\n",
            "Epoch 74/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 7.1684 - mae: 2.0844 - val_loss: 6.6660 - val_mae: 2.0141\n",
            "Epoch 75/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7.0736 - mae: 2.0727 - val_loss: 6.3251 - val_mae: 1.9590\n",
            "Epoch 76/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 6.9268 - mae: 2.0510 - val_loss: 6.2471 - val_mae: 1.9470\n",
            "Epoch 77/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.7234 - mae: 2.0190 - val_loss: 6.0634 - val_mae: 1.9149\n",
            "Epoch 78/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.6551 - mae: 2.0088 - val_loss: 5.8058 - val_mae: 1.8735\n",
            "Epoch 79/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.4189 - mae: 1.9705 - val_loss: 5.6845 - val_mae: 1.8521\n",
            "Epoch 80/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.2889 - mae: 1.9489 - val_loss: 5.4996 - val_mae: 1.8186\n",
            "Epoch 81/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6.2023 - mae: 1.9346 - val_loss: 5.5080 - val_mae: 1.8216\n",
            "Epoch 82/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6.0466 - mae: 1.9077 - val_loss: 5.4177 - val_mae: 1.8066\n",
            "Epoch 83/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5.9332 - mae: 1.8902 - val_loss: 5.4203 - val_mae: 1.8092\n",
            "Epoch 84/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5.8291 - mae: 1.8724 - val_loss: 5.4538 - val_mae: 1.8159\n",
            "Epoch 85/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.7802 - mae: 1.8564 - val_loss: 5.3525 - val_mae: 1.7986\n",
            "Epoch 86/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.6909 - mae: 1.8502 - val_loss: 5.5412 - val_mae: 1.8301\n",
            "Epoch 87/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.7056 - mae: 1.8511 - val_loss: 5.6585 - val_mae: 1.8542\n",
            "Epoch 88/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.6369 - mae: 1.8406 - val_loss: 5.6813 - val_mae: 1.8545\n",
            "Epoch 89/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.6142 - mae: 1.8337 - val_loss: 5.6082 - val_mae: 1.8446\n",
            "Epoch 90/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.5955 - mae: 1.8298 - val_loss: 5.3542 - val_mae: 1.7947\n",
            "Epoch 91/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.5992 - mae: 1.8269 - val_loss: 5.1429 - val_mae: 1.7590\n",
            "Epoch 92/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.4345 - mae: 1.7986 - val_loss: 5.0589 - val_mae: 1.7374\n",
            "Epoch 93/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.2998 - mae: 1.7720 - val_loss: 4.7501 - val_mae: 1.6702\n",
            "Epoch 94/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.1604 - mae: 1.7525 - val_loss: 4.8652 - val_mae: 1.6907\n",
            "Epoch 95/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.0911 - mae: 1.7432 - val_loss: 5.4176 - val_mae: 1.7915\n",
            "Epoch 96/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.2283 - mae: 1.7669 - val_loss: 4.8257 - val_mae: 1.6729\n",
            "Epoch 97/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.4128 - mae: 1.7963 - val_loss: 4.7776 - val_mae: 1.6759\n",
            "Epoch 98/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.0762 - mae: 1.7375 - val_loss: 4.6316 - val_mae: 1.6481\n",
            "Epoch 99/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.9528 - mae: 1.7142 - val_loss: 4.4732 - val_mae: 1.6106\n",
            "Epoch 100/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8757 - mae: 1.6976 - val_loss: 4.4679 - val_mae: 1.6104\n",
            "Epoch 101/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7622 - mae: 1.6757 - val_loss: 4.4592 - val_mae: 1.6105\n",
            "Epoch 102/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6845 - mae: 1.6599 - val_loss: 4.4570 - val_mae: 1.6114\n",
            "Epoch 103/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6452 - mae: 1.6523 - val_loss: 4.4684 - val_mae: 1.6156\n",
            "Epoch 104/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6242 - mae: 1.6487 - val_loss: 4.5261 - val_mae: 1.6289\n",
            "Epoch 105/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5771 - mae: 1.6392 - val_loss: 4.4630 - val_mae: 1.6138\n",
            "Epoch 106/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5423 - mae: 1.6319 - val_loss: 4.4749 - val_mae: 1.6154\n",
            "Epoch 107/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.4877 - mae: 1.6222 - val_loss: 4.5305 - val_mae: 1.6301\n",
            "Epoch 108/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.5133 - mae: 1.6254 - val_loss: 4.5474 - val_mae: 1.6346\n",
            "Epoch 109/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.4585 - mae: 1.6112 - val_loss: 4.4874 - val_mae: 1.6257\n",
            "Epoch 110/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.4284 - mae: 1.6060 - val_loss: 4.4308 - val_mae: 1.6113\n",
            "Epoch 111/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3840 - mae: 1.5975 - val_loss: 4.1928 - val_mae: 1.5595\n",
            "Epoch 112/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.3286 - mae: 1.5881 - val_loss: 4.1627 - val_mae: 1.5552\n",
            "Epoch 113/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3247 - mae: 1.5871 - val_loss: 4.1870 - val_mae: 1.5573\n",
            "Epoch 114/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3028 - mae: 1.5823 - val_loss: 4.1323 - val_mae: 1.5463\n",
            "Epoch 115/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.3095 - mae: 1.5840 - val_loss: 4.0267 - val_mae: 1.5204\n",
            "Epoch 116/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4369 - mae: 1.6085 - val_loss: 4.2521 - val_mae: 1.5837\n",
            "Epoch 117/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.4729 - mae: 1.6185 - val_loss: 4.4026 - val_mae: 1.6244\n",
            "Epoch 118/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.3312 - mae: 1.5943 - val_loss: 4.3786 - val_mae: 1.6204\n",
            "Epoch 119/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4.2721 - mae: 1.5852 - val_loss: 4.2332 - val_mae: 1.5843\n",
            "Epoch 120/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2701 - mae: 1.5841 - val_loss: 4.1103 - val_mae: 1.5547\n",
            "Epoch 121/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2873 - mae: 1.5873 - val_loss: 4.0062 - val_mae: 1.5293\n",
            "Epoch 122/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2467 - mae: 1.5799 - val_loss: 3.9204 - val_mae: 1.5061\n",
            "Epoch 123/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.1590 - mae: 1.5618 - val_loss: 3.9680 - val_mae: 1.5177\n",
            "Epoch 124/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1255 - mae: 1.5547 - val_loss: 3.9010 - val_mae: 1.4995\n",
            "Epoch 125/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1022 - mae: 1.5492 - val_loss: 3.8260 - val_mae: 1.4768\n",
            "Epoch 126/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0900 - mae: 1.5467 - val_loss: 3.9133 - val_mae: 1.4945\n",
            "Epoch 127/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.0713 - mae: 1.5416 - val_loss: 3.8451 - val_mae: 1.4817\n",
            "Epoch 128/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.0390 - mae: 1.5361 - val_loss: 3.9958 - val_mae: 1.5002\n",
            "Epoch 129/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9770 - mae: 1.5195 - val_loss: 3.9657 - val_mae: 1.4923\n",
            "Epoch 130/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9539 - mae: 1.5162 - val_loss: 3.9370 - val_mae: 1.4917\n",
            "Epoch 131/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9553 - mae: 1.5154 - val_loss: 3.9578 - val_mae: 1.4935\n",
            "Epoch 132/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3.9336 - mae: 1.5126 - val_loss: 3.9141 - val_mae: 1.4829\n",
            "Epoch 133/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3.9387 - mae: 1.5135 - val_loss: 3.9338 - val_mae: 1.4865\n",
            "Epoch 134/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3.9099 - mae: 1.5079 - val_loss: 3.9210 - val_mae: 1.4841\n",
            "Epoch 135/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8888 - mae: 1.5032 - val_loss: 4.0483 - val_mae: 1.5168\n",
            "Epoch 136/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8900 - mae: 1.5037 - val_loss: 4.0502 - val_mae: 1.5115\n",
            "Epoch 137/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.8892 - mae: 1.5057 - val_loss: 3.9516 - val_mae: 1.4947\n",
            "Epoch 138/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8473 - mae: 1.4971 - val_loss: 3.9373 - val_mae: 1.4913\n",
            "Epoch 139/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8295 - mae: 1.4935 - val_loss: 3.8270 - val_mae: 1.4735\n",
            "Epoch 140/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.8046 - mae: 1.4867 - val_loss: 3.9928 - val_mae: 1.5002\n",
            "Epoch 141/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8534 - mae: 1.5019 - val_loss: 4.4402 - val_mae: 1.5923\n",
            "Epoch 142/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9386 - mae: 1.5176 - val_loss: 3.7968 - val_mae: 1.4708\n",
            "Epoch 143/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8097 - mae: 1.4921 - val_loss: 3.9222 - val_mae: 1.4889\n",
            "Epoch 144/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8416 - mae: 1.4995 - val_loss: 4.2625 - val_mae: 1.5717\n",
            "Epoch 145/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.7946 - mae: 1.4869 - val_loss: 4.1005 - val_mae: 1.5280\n",
            "Epoch 146/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3.7622 - mae: 1.4800 - val_loss: 4.3071 - val_mae: 1.5929\n",
            "Epoch 147/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.8330 - mae: 1.4951 - val_loss: 3.7887 - val_mae: 1.4630\n",
            "Epoch 148/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7911 - mae: 1.4852 - val_loss: 3.9485 - val_mae: 1.4857\n",
            "Epoch 149/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7971 - mae: 1.4869 - val_loss: 4.1267 - val_mae: 1.5276\n",
            "Epoch 150/150\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.7980 - mae: 1.4871 - val_loss: 4.1531 - val_mae: 1.5545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MSE')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "f7Kkdw8nNLxU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}